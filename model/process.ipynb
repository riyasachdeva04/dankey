{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('memegenerator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meme ID</th>\n",
       "      <th>Archived URL</th>\n",
       "      <th>Base Meme Name</th>\n",
       "      <th>Meme Page URL</th>\n",
       "      <th>MD5 Hash</th>\n",
       "      <th>File Size (In Bytes)</th>\n",
       "      <th>Alternate Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10509464</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Spiderman Approves</td>\n",
       "      <td>http://memegenerator.net/instance/10509464</td>\n",
       "      <td>5be4b65cc32d3a57be5b6693bb519155</td>\n",
       "      <td>24093.0</td>\n",
       "      <td>seems legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12285257</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Alright Then Business Kid</td>\n",
       "      <td>http://memegenerator.net/instance/12285257</td>\n",
       "      <td>e2eef6626b3fdb369df23a5fabd99df4</td>\n",
       "      <td>25513.0</td>\n",
       "      <td>Fret not I stayed at a Holiday Inn Express las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20612245</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Archer</td>\n",
       "      <td>http://memegenerator.net/instance/20612245</td>\n",
       "      <td>a6b7db4574325013f05bf1aabdcaeded</td>\n",
       "      <td>31157.0</td>\n",
       "      <td>hello airplanes? yeah, this is blimps. Yeah, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20614628</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Futurama Fry</td>\n",
       "      <td>http://webarchive.loc.gov/all/0/http://memegen...</td>\n",
       "      <td>be75a0451f607d65df43813257d90f7a</td>\n",
       "      <td>50056.0</td>\n",
       "      <td>LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24194267</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>One Does Not Simply</td>\n",
       "      <td>http://memegenerator.net/instance/24194267</td>\n",
       "      <td>2437b5ae9c4741c2e6f249f3f731dee2</td>\n",
       "      <td>24209.0</td>\n",
       "      <td>one does not simply  put toothpaste back in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Meme ID                                       Archived URL  \\\n",
       "0  10509464  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "1  12285257  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "2  20612245  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "3  20614628  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "4  24194267  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "\n",
       "              Base Meme Name  \\\n",
       "0         Spiderman Approves   \n",
       "1  Alright Then Business Kid   \n",
       "2                     Archer   \n",
       "3               Futurama Fry   \n",
       "4        One Does Not Simply   \n",
       "\n",
       "                                       Meme Page URL  \\\n",
       "0         http://memegenerator.net/instance/10509464   \n",
       "1         http://memegenerator.net/instance/12285257   \n",
       "2         http://memegenerator.net/instance/20612245   \n",
       "3  http://webarchive.loc.gov/all/0/http://memegen...   \n",
       "4         http://memegenerator.net/instance/24194267   \n",
       "\n",
       "                           MD5 Hash  File Size (In Bytes)  \\\n",
       "0  5be4b65cc32d3a57be5b6693bb519155               24093.0   \n",
       "1  e2eef6626b3fdb369df23a5fabd99df4               25513.0   \n",
       "2  a6b7db4574325013f05bf1aabdcaeded               31157.0   \n",
       "3  be75a0451f607d65df43813257d90f7a               50056.0   \n",
       "4  2437b5ae9c4741c2e6f249f3f731dee2               24209.0   \n",
       "\n",
       "                                      Alternate Text  \n",
       "0                                        seems legit  \n",
       "1  Fret not I stayed at a Holiday Inn Express las...  \n",
       "2  hello airplanes? yeah, this is blimps. Yeah, y...  \n",
       "3  LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...  \n",
       "4  one does not simply  put toothpaste back in th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Meme ID', 'Archived URL', 'MD5 Hash', 'File Size (In Bytes)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Meme Name</th>\n",
       "      <th>Meme Page URL</th>\n",
       "      <th>Alternate Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiderman Approves</td>\n",
       "      <td>http://memegenerator.net/instance/10509464</td>\n",
       "      <td>seems legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alright Then Business Kid</td>\n",
       "      <td>http://memegenerator.net/instance/12285257</td>\n",
       "      <td>Fret not I stayed at a Holiday Inn Express las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archer</td>\n",
       "      <td>http://memegenerator.net/instance/20612245</td>\n",
       "      <td>hello airplanes? yeah, this is blimps. Yeah, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futurama Fry</td>\n",
       "      <td>http://webarchive.loc.gov/all/0/http://memegen...</td>\n",
       "      <td>LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One Does Not Simply</td>\n",
       "      <td>http://memegenerator.net/instance/24194267</td>\n",
       "      <td>one does not simply  put toothpaste back in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Base Meme Name  \\\n",
       "0         Spiderman Approves   \n",
       "1  Alright Then Business Kid   \n",
       "2                     Archer   \n",
       "3               Futurama Fry   \n",
       "4        One Does Not Simply   \n",
       "\n",
       "                                       Meme Page URL  \\\n",
       "0         http://memegenerator.net/instance/10509464   \n",
       "1         http://memegenerator.net/instance/12285257   \n",
       "2         http://memegenerator.net/instance/20612245   \n",
       "3  http://webarchive.loc.gov/all/0/http://memegen...   \n",
       "4         http://memegenerator.net/instance/24194267   \n",
       "\n",
       "                                      Alternate Text  \n",
       "0                                        seems legit  \n",
       "1  Fret not I stayed at a Holiday Inn Express las...  \n",
       "2  hello airplanes? yeah, this is blimps. Yeah, y...  \n",
       "3  LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...  \n",
       "4  one does not simply  put toothpaste back in th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_headers = ['file_name', 'link', 'text', 'text2', 'sentiment', 'sarcasm', 'offensive', 'motivational', 'positive/negative']\n",
    "df2 = pd.read_excel('data_7000_actual.xlsx', header=None, names=custom_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>positive/negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_year_2r94rv.jpg</td>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_year_10-year-challenge_1547788782.jpeg</td>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_year_10yearchallenge-5c75f8b946e0fb0001edc7...</td>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_year_10-year-challenge-sweet-dee-edition-40...</td>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_year_10-year-challenge-with-no-filter-47-hi...</td>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0                                 10_year_2r94rv.jpg   \n",
       "1          10_year_10-year-challenge_1547788782.jpeg   \n",
       "2  10_year_10yearchallenge-5c75f8b946e0fb0001edc7...   \n",
       "3  10_year_10-year-challenge-sweet-dee-edition-40...   \n",
       "4  10_year_10-year-challenge-with-no-filter-47-hi...   \n",
       "\n",
       "                                                link  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                                text  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3             10 Year Challenge - Sweet Dee Edition    \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                               text2   sentiment  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
       "1  The best of #10 YearChallenge! Completed in le...   not_funny   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
       "3             10 Year Challenge - Sweet Dee Edition   very_funny   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational positive/negative  \n",
       "0          general   not_offensive  not_motivational          positive  \n",
       "1          general   not_offensive      motivational          positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['file_name', 'text2', ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text']=df2['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>positive/negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>look there my friend lightyear now all sohalik...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>the best of #10 yearchallenge! completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>sam thorne @strippin ( follow follow saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 year challenge - sweet dee edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 year challenge with no filter 47 hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                                text   sentiment  \\\n",
       "0  look there my friend lightyear now all sohalik...   hilarious   \n",
       "1  the best of #10 yearchallenge! completed in le...   not_funny   \n",
       "2  sam thorne @strippin ( follow follow saw every...  very_funny   \n",
       "3             10 year challenge - sweet dee edition   very_funny   \n",
       "4  10 year challenge with no filter 47 hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational positive/negative  \n",
       "0          general   not_offensive  not_motivational          positive  \n",
       "1          general   not_offensive      motivational          positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6520 entries, 0 to 6519\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   link               6520 non-null   object\n",
      " 1   text               6355 non-null   object\n",
      " 2   sentiment          6520 non-null   object\n",
      " 3   sarcasm            6520 non-null   object\n",
      " 4   offensive          6520 non-null   object\n",
      " 5   motivational       6520 non-null   object\n",
      " 6   positive/negative  6520 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 356.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"shutup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (0.19.3)\n",
      "Requirement already satisfied: filelock in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57652 entries, 0 to 57651\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Base Meme Name  57645 non-null  object\n",
      " 1   Meme Page URL   57377 non-null  object\n",
      " 2   Alternate Text  57347 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Alternate Text'] = df['Alternate Text'].apply(lambda x: str(x) if x is not None else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset 1\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "def get_meme1(text):\n",
    "\n",
    "    # Load the Universal Sentence Encoder\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    # Encode messages and meme texts\n",
    "    message_embedding = model.encode(text)\n",
    "    meme_embeddings = model.encode(df['Alternate Text'].astype(str).tolist())\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = util.pytorch_cos_sim(message_embedding, meme_embeddings)[0]\n",
    "\n",
    "    # Find the index of the most similar meme\n",
    "    most_similar_index = similarities.argmax().item()\n",
    "\n",
    "    # Get the most similar meme text\n",
    "    most_similar_meme = df['Alternate Text'][most_similar_index]\n",
    "\n",
    "    print(\"Most similar meme:\", most_similar_meme)\n",
    "\n",
    "    return most_similar_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 690/690 [00:00<00:00, 1.48MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 601kB/s]\n",
      "README.md: 100%|██████████| 3.69k/3.69k [00:00<00:00, 14.1MB/s]\n",
      "config.json: 100%|██████████| 629/629 [00:00<00:00, 3.29MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 502kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:01<00:00, 53.1MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 225kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 267kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.07MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 728kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 539kB/s]\n",
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 476kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar meme: Hello shut up\n"
     ]
    }
   ],
   "source": [
    "indx = get_meme1(text)\n",
    "link = df['Meme Page URL'][indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://webarchive.loc.gov/all/0/http://memegenerator.net/instance/25781211\n"
     ]
    }
   ],
   "source": [
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_url(link):\n",
    "    if link.startswith(\"http://webarchive\"):\n",
    "        index = link.find(\"http\", len(\"http://webarchive\"))\n",
    "\n",
    "        if index != -1:\n",
    "            new_link = link[index:]\n",
    "            return new_link\n",
    "    return link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = modify_url(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://webarchive.loc.gov/all/0/http://memegenerator.net/instance/25781211\n"
     ]
    }
   ],
   "source": [
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>positive/negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>look there my friend lightyear now all sohalik...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>the best of #10 yearchallenge! completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>sam thorne @strippin ( follow follow saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 year challenge - sweet dee edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 year challenge with no filter 47 hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                                text   sentiment  \\\n",
       "0  look there my friend lightyear now all sohalik...   hilarious   \n",
       "1  the best of #10 yearchallenge! completed in le...   not_funny   \n",
       "2  sam thorne @strippin ( follow follow saw every...  very_funny   \n",
       "3             10 year challenge - sweet dee edition   very_funny   \n",
       "4  10 year challenge with no filter 47 hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational positive/negative  \n",
       "0          general   not_offensive  not_motivational          positive  \n",
       "1          general   not_offensive      motivational          positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "funny         2291\n",
       "very_funny    2075\n",
       "not_funny     1550\n",
       "hilarious      604\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['sentiment'] != 'not_funny']\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "funny         2291\n",
       "very_funny    2075\n",
       "hilarious      604\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarcasm\n",
       "general            2689\n",
       "twisted_meaning    1212\n",
       "not_sarcastic       859\n",
       "very_twisted        210\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sarcasm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['sarcasm'] != 'not_sarcastic']\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meme2(text):\n",
    "\n",
    "    # Load the Universal Sentence Encoder\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    # Encode messages and meme texts\n",
    "    message_embedding = model.encode(text)\n",
    "    meme_embeddings = model.encode(df2['text'].astype(str).tolist())\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = util.pytorch_cos_sim(message_embedding, meme_embeddings)[0]\n",
    "\n",
    "    # Find the index of the most similar meme\n",
    "    most_similar_index = similarities.argmax().item()\n",
    "\n",
    "    # Get the most similar meme text\n",
    "    most_similar_meme = df2['text'][most_similar_index]\n",
    "\n",
    "    print(\"Most similar meme:\", most_similar_meme)\n",
    "\n",
    "    return most_similar_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar meme: shut up\n"
     ]
    }
   ],
   "source": [
    "indx2 = get_meme2(text)\n",
    "link2 = df2['link'][indx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.kym-cdn.com/photos/images/original/001/382/718/f4d.jpeg\n"
     ]
    }
   ],
   "source": [
    "print(link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: jinja2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# def calculate_similarity(text1, text2):\n",
    "#         nlp = spacy.load('/path/to/en_core_web_sm-2.2.0')\n",
    "        \n",
    "#         doc1 = nlp(text1)\n",
    "#         doc2 = nlp(text2)\n",
    "\n",
    "#         # Calculate cosine similarity between the two documents\n",
    "#         similarity = doc1.similarity(doc2)\n",
    "#         return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1 = df['Alternate Text'][indx]\n",
    "# text2 = df2['text'][indx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score1 = calculate_similarity(text, text1)\n",
    "# score2 = calculate_similarity(text, text2)\n",
    "\n",
    "# final_link = \"\"\n",
    "\n",
    "# if score1 > score2:\n",
    "#     final_link = link1\n",
    "# else:\n",
    "#     final_link = link2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "final_link = random.choice([link1, link2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.kym-cdn.com/photos/images/original/001/382/718/f4d.jpeg\n"
     ]
    }
   ],
   "source": [
    "print(final_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
